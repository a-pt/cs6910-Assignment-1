{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stochastic_grad.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cs20m016/cs6910-Assignment-1/blob/main/stochastic_grad.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hl7y_jrMRKdN"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "import math"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nNWmCVoTj6v"
      },
      "source": [
        "from keras.datasets import fashion_mnist"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi_Sb0I_Tj0z"
      },
      "source": [
        "(train_X,train_Y), (test_X,test_Y)= fashion_mnist.load_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPCY-F81Tjx5",
        "outputId": "7f848e3b-01ba-42af-bb11-c84f49e6265a"
      },
      "source": [
        "train_X.shape, train_Y.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOvTxrV-Tjnd"
      },
      "source": [
        "train_X = train_X[:]/255\r\n",
        "test_Y = test_Y[:]/255"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o25YyGvVmoB_"
      },
      "source": [
        "train_X=[train_X[i].flatten() for i in range(len(train_X))]\r\n",
        "test_X=[test_X[i].flatten() for i in range(len(test_X))]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hULrbWpnnTWu",
        "outputId": "db179f3f-7e36-481c-dcd2-3db585958347"
      },
      "source": [
        "np.shape(train_X), np.shape(train_Y), np.shape(test_X), np.shape(test_Y)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000,), (10000, 784), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FK13NvWtJrqS",
        "outputId": "1e3c28cc-339f-4958-c53f-cc1d9b4598e0"
      },
      "source": [
        "train_samples=len(train_X)\r\n",
        "test_samples=len(test_X)\r\n",
        "xlen=len(train_X[0])\r\n",
        "print(xlen)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sED-2jH13oR4"
      },
      "source": [
        "#N: number of inputs\r\n",
        "#N = input()\r\n",
        "N = 5\r\n",
        "#L: number of layers\r\n",
        "#L = input()\r\n",
        "L = 3\r\n",
        "#H = number of hidden layers\r\n",
        "Hid = L-1\r\n",
        "#K = number of classes\r\n",
        "K = 10"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFv1lhLwmEQ4"
      },
      "source": [
        "def initialize_weights(n_input, n_hidden_layer, n_output,neurons_hl):\r\n",
        "    W = list()\r\n",
        "    W.append([[random.random() for j in range(n_input)]for i in range(neurons_hl)])\r\n",
        "    for i in range(n_hidden_layer-1):\r\n",
        "        W.append([[random.random() for j in range(neurons_hl)]for i in range(neurons_hl)])\r\n",
        "    W.append([[random.random() for j in range(neurons_hl)]for i in range(n_output)])\r\n",
        "    return W\r\n",
        "#W=initialize_weights(len(train_X[0]),Hid,10,N)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndolgSz_mEE1"
      },
      "source": [
        "def initialize_bias(n_input, n_hidden_layer, n_output,n_neurons):\r\n",
        "    b=list()\r\n",
        "    for i in range(n_hidden_layer):\r\n",
        "        b.append([random.random() for i in range(n_neurons)])\r\n",
        "    b.append([random.random() for i in range(n_output)])\r\n",
        "    return b\r\n",
        "#b = initialize_bias(len(train_X[0]),L-1,10,N)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjVLQ5S-ceVV"
      },
      "source": [
        "def sigmoid(a):\r\n",
        "  h = []\r\n",
        "  for a1 in a:\r\n",
        "    h.append(1.0/(1.0 + np.exp(-a1)))\r\n",
        "  return h"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImJ37p17ci75"
      },
      "source": [
        "def softmax(a):\r\n",
        "  y = []\r\n",
        "  sum = 0\r\n",
        "  for a1 in a:\r\n",
        "    sum+= np.exp(a1)\r\n",
        "  for a1 in a:\r\n",
        "    y.append(np.exp(a1)/sum)\r\n",
        "  return y"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz1yvps-VRiB"
      },
      "source": [
        "def feed_forward_prop(input,W,b,L):\r\n",
        "  H=[]\r\n",
        "  A=[]\r\n",
        "  h=input\r\n",
        "  H.append(h)\r\n",
        "  A.append([0])\r\n",
        "  for i in range(1,L):\r\n",
        "      a=b[i-1]+np.matmul(W[i-1],H[i-1])\r\n",
        "      A.append(a)\r\n",
        "      h=sigmoid(a)\r\n",
        "      H.append(h)\r\n",
        "  aL=b[L-1]+np.matmul(W[L-1],H[L-1])\r\n",
        "  A.append(aL)\r\n",
        "  hL=softmax(aL)\r\n",
        "  H.append(hL)\r\n",
        "  y_hat = hL\r\n",
        "  return H,A,y_hat"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8s6gvlIiVReo"
      },
      "source": [
        "W= initialize_weights(xlen,L-1,K,N)\r\n",
        "B= initialize_bias(xlen,L-1,K,N)\r\n",
        "H,A,y_hat = feed_forward_prop(x,W,B,L)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AznDo-x7CvYm",
        "outputId": "89101bae-321a-4138-be88-71a8b45e0bb2"
      },
      "source": [
        "y_hat"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01369696053914406,\n",
              " 0.13729945213387804,\n",
              " 0.021308227674230497,\n",
              " 0.18873610621531173,\n",
              " 0.11029076365551499,\n",
              " 0.14726757508893126,\n",
              " 0.2485638883669086,\n",
              " 0.013084375838844278,\n",
              " 0.099287151477072,\n",
              " 0.020465499010164433]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLqwSV1JIkn3"
      },
      "source": [
        "def cmp(e):\r\n",
        "  g=1.0/(1.0 + np.exp(-e))\r\n",
        "  return g*(1-g)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2oTNkrtIkkZ"
      },
      "source": [
        "def diff_sigmoid(a):\r\n",
        "    res=[]\r\n",
        "    for el in a:\r\n",
        "      res.append(cmp(el))\r\n",
        "    return res"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-NzdyUTIkh9"
      },
      "source": [
        "def back_propogation(H,A,y_hat,label):\r\n",
        "    W_grad=list()\r\n",
        "    B_grad=list()\r\n",
        "    one_hot_y=np.zeros(K)\r\n",
        "    one_hot_y[label]+=1\r\n",
        "    ak_grad = y_hat-one_hot_y\r\n",
        "    for k in range(L,0,-1):\r\n",
        "        w_grad=np.matmul(np.matrix(ak_grad).T,np.matrix(H[k-1]))\r\n",
        "        W_grad.append(w_grad)\r\n",
        "        B_grad.append(ak_grad)\r\n",
        "        if k != 1:\r\n",
        "            h_grad=np.matmul(np.transpose(W[k-1]),ak_grad)\r\n",
        "            ak_grad=np.multiply(h_grad,diff_sigmoid(A[k-1]))\r\n",
        "    return W_grad,B_grad"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMr1twufIq-J"
      },
      "source": [
        "# print(np.shape(W_grad[0]))\r\n",
        "# print(np.shape(W_grad[1]))\r\n",
        "# print(np.shape(W_grad[2]))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDR3PyAdIq6z"
      },
      "source": [
        "# print(np.shape(B_grad[0]))\r\n",
        "# print(np.shape(B_grad[1]))\r\n",
        "# print(np.shape(B_grad[2]))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn-NFN39Iq37"
      },
      "source": [
        "eta=0.001"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lhjvit16idl5"
      },
      "source": [
        "# stochastic gradient descent"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_gk5akidiu"
      },
      "source": [
        "def stochastic_gradient_descent():\r\n",
        "    t=0\r\n",
        "    max_iterations=3\r\n",
        "    W= initialize_weights(xlen,L-1,K,N)\r\n",
        "    B= initialize_bias(xlen,L-1,K,N)\r\n",
        "    loss=list()\r\n",
        "    error = 0.0\r\n",
        "    while (t<max_iterations):\r\n",
        "      for i in range(train_samples):\r\n",
        "        eta_wgrad=list()\r\n",
        "        eta_bgrad=list()\r\n",
        "        for l in range(L):\r\n",
        "            eta_wgrad.append(np.zeros(shape=np.shape(W[l])).tolist())\r\n",
        "            eta_bgrad.append(np.zeros(shape=np.shape(B[l])).tolist())\r\n",
        "            H,A,y_hat = feed_forward_prop(train_X[i],W,B,L)\r\n",
        "            W_grad,B_grad=back_propogation(H,A,y_hat,train_Y[i])\r\n",
        "            W_grad=W_grad[::-1]\r\n",
        "            B_grad=B_grad[::-1]\r\n",
        "            error+=(-math.log(y_hat[train_Y[i]]))\r\n",
        "            loss.append(error)\r\n",
        "        for l in range(L):\r\n",
        "            eta_wgrad[l]=(np.matrix(eta_wgrad[l])+np.multiply(eta,W_grad[l])).tolist()\r\n",
        "            eta_bgrad[l]=(eta_bgrad[l]+np.multiply(eta,B_grad[l])).tolist()\r\n",
        "        for l in range(L):\r\n",
        "            W[l]=(np.matrix(W[l])-np.matrix(eta_wgrad[l])).tolist()\r\n",
        "            B[l]=np.subtract(B[l],eta_bgrad[l])       \r\n",
        "      t=t+1\r\n",
        "      print('Epoch',t)\r\n",
        "    return W,B,loss"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxWSCjeE5aNj"
      },
      "source": [
        "W_s,B_s,loss_s = stochastic_gradient_descent()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pFR7YhTnVMc"
      },
      "source": [
        "plt.plot(np.arange(1,len(loss_s)+1),loss_s)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}